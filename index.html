<!DOCTYPE HTML>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Anirudh S Chakravarthy</title>
  
  <meta name="author" content="Anirudh S Chakravarthy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  
  <script src='https://kit.fontawesome.com/a076d05399.js'></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/cmu_logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Anirudh S Chakravarthy</name>
              </p>
              <p>
                I'm a Member of Technical Staff at <a href="https://labs.amazon.science/">Amazon AGI Labs</a>, researching and building reliable computer-use agents.
                I graduated with my Master of Science in Computer Vision (MSCV) at the <a href="https://www.ri.cmu.edu/">Robotics Institute</a>, <a href="https://www.cmu.edu/">Carnegie Mellon University</a> (CMU), where I was advised by <a href="http://www.cs.cmu.edu/~deva/">Prof. Deva Ramanan</a>. 
                My research at CMU focused on extending panoptic segmentation into the open world and discovering novel objects without explicit supervision.
              </p>
              <p>
                I am fortunate to have received mentorship at every step of my journey. If you think I can help you, please reach out!
              </p>
              <p>
                <!--In 2022, I was an intern in the Perception Team at <a href="https://www.getcruise.com">Cruise</a> where my research enabled adaptive task weight balancing during train-time for multi-task learning. I also proposed a task-incremental learning method which benefitted from my adaptive task balancing work and achieved state-of-the-art performance on internal metrics. -->
              </p>
              <p>
                <!-- Previously, I completed my undergraduate degree in Computer Science at <a href="https://www.bits-pilani.ac.in/" >BITS Pilani</a>, India.  -->
                <!-- As an undergrad, I had the pleasure of working with <a href="https://vcg.seas.harvard.edu/people/hanspeter-pfister">Prof. Hanspeter Pfister</a> at <a href="https://vcg.seas.harvard.edu/">Harvard VCG</a> and <a href="https://vision.ai.illinois.edu/narendra-ahuja/">Prof. Narendra Ahuja</a> at <a href="https://vision.ai.illinois.edu/">UIUC CVRL</a>. -->
              </p>
              
              <p style="text-align:center">
                <a href="mailto:anirudh.s.chakravarthy@gmail.com">Email</a> &nbsp|&nbsp
                <a href="data/Anirudh Chakravarthy resume.pdf">Resume</a> &nbsp|&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=FhPaTZEAAAAJ">Google Scholar</a> &nbsp|&nbsp
                <a href="https://www.linkedin.com/in/anirudh-chakravarthy/">LinkedIn</a> &nbsp|&nbsp
                <a href="https://x.com/anirudhchak/">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Anirudh_circle.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Anirudh_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="10"></tbody>
          <tr>

            <td align="center" width="16%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
              <a href="https://labs.amazon.science/"><img src = "images/amazon_logo.png" width="120%"></a>
            </td>
            
            <td align="center" width="16%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
              <a href="https://www.getcruise.com/"><img src = "images/cruise_logo.png" width="120%"></a>
            </td>

            <td align="center" width="16%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
              <a href="https://www.cmu.edu/"><img src = "images/cmu_logo.png" width="90%"></a>
            </td>

            <td align="center" width="16%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
              <a href="https://www.harvard.edu/"><img src = "images/Harvard_logo.png" width="90%"></a>
            </td>
            
            <td align="center" width="16%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
              <a href="https://illinois.edu/"><img src = "images/uiuc_logo.png" width="120%"></a>

            <td align="center" width="16%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
              <a href="https://www.bits-pilani.ac.in/"><img src = "images/BITS_Pilani-Logo.png" width="90%"></a>
            </td>
            
          </tr>
            
        </tbody</table>
        
        <br><br>
        <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">

              <div class="col-md-7">
                <heading>Education</heading>
                <ul class="ul-edu fa-ul">
                  
                  <li>
                    <i class="fa-li fas fa-graduation-cap"></i>
                    <div class="description">
                      <p><em>M.S in Computer Vision</em> <br> Carnegie Mellon University, USA</p>
                    </div>
                  </li>

                  <li>
                    <i class="fa-li fas fa-graduation-cap"></i>
                    <div class="description">
                      <p><em>B.E in Computer Science</em> <br> BITS Pilani, India</p>
                    </div>
                  </li>
                </ul>
              </div>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <!-- <p> -->
                <!-- My current research at CMU and Argo AI is focused on discovering novel objects in an open-world setting.  -->
              <!-- </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

			        <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ddp_image'>
                  <img src='images/profit_teaser.png' width="200"></div>
                <img src='images/profit_teaser.png' width="200">
              </div>
              <script type="text/javascript">
                function ddp_start() {
                  document.getElementById('ddp_image').style.opacity = "1";
                }
        
                function ddp_stop() {
                  document.getElementById('ddp_image').style.opacity = "0";
                }
                ddp_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>PROFIT: A Specialized Optimizer for Deep Fine Tuning</papertitle>
              </a>
              <br>
              <strong>Anirudh Chakravarthy</strong>,
              <a href="https://kylezheng.org/">Shuai Kyle Zheng</a>,
              Xin Huang, 
              <a href="https://people.csail.mit.edu/sachih/home/">Sachithra Hemachandra</a>, 
	      	  Xiao Zhang,
              Yuning Chai, 
              Zhao Chen
              <br>
              <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2025
              <br>
              <a href="https://arxiv.org/pdf/2412.01930">[arxiv]</a>
              
              <p></p>
              <p>
              The fine-tuning of pre-trained models has become ubiquitous in generative AI, computer vision, and robotics. We present PROFIT, the first optimizer designed to incrementally fine-tune converged models on new tasks and/or datasets.
            </p>
          </td>
        </tr>

          <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ddp_image'>
                  <img src='images/lipsow_teaser.png' width="200"></div>
                <img src='images/lipsow_teaser.png' width="200">
              </div>
              <script type="text/javascript">
                function ddp_start() {
                  document.getElementById('ddp_image').style.opacity = "1";
                }
        
                function ddp_stop() {
                  document.getElementById('ddp_image').style.opacity = "0";
                }
                ddp_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2409.14273">
                <papertitle>Lidar Panoptic Segmentation in an Open World</papertitle>
              </a>
              <br>
              <strong>Anirudh Chakravarthy</strong>,
              <a href="https://g-meghana-reddy.github.io">Meghana Reddy Ganesina</a>,
              <a href="https://peiyunh.github.io">Peiyun Hu</a>, 
              <a href="https://dvl.in.tum.de/team/lealtaixe/">Laura Leal-Taix√©</a>, 
              <a href="https://aimerykong.github.io/">Shu Kong</a>, 
              <a href="https://www.cs.cmu.edu/~deva/">Deva Ramanan</a>, 
              <a href="https://aljosaosep.github.io">Aljosa Osep</a>
              <br>
              <em>International Journal of Computer Vision</em>, 2024
              <be>
	      <br>
	      <a href="https://link.springer.com/article/10.1007/s11263-024-02166-9">[pdf]</a>
	      <a href="https://arxiv.org/pdf/2409.14273">[arxiv]</a>
              <a href="https://mscvprojects.ri.cmu.edu/2022team1/">[project page]</a>
              <a href="https://github.com/g-meghana-reddy/open-world-panoptic-segmentation">[code]</a>
              
              <p></p>
              <p>
               Current Lidar Panoptic Segmentation (LPS) methods make an unrealistic assumption that the semantic class vocabulary is fixed in the real world, but in fact, class ontologies usually evolve over time as robots encounter instances of novel classes. To address this unrealistic assumption, we study LPS in the Open World (LiPSOW).
            </p>
          </td>
        </tr>

          <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ddp_image'>
                  <img src='images/youmvos_teaser.png' width="200"></div>
                <img src='images/youmvos_teaser.png' width="200">
              </div>
              <script type="text/javascript">
                function ddp_start() {
                  document.getElementById('ddp_image').style.opacity = "1";
                }
        
                function ddp_stop() {
                  document.getElementById('ddp_image').style.opacity = "0";
                }
                ddp_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://vcg.seas.harvard.edu/publications/youmvos/paper">
                <papertitle>YouMVOS: An Actor-centric Multi-shot Video Object Segmentation Dataset</papertitle>
              </a>
              <br>
              <a href="https://donglaiw.github.io/">Donglai Wei</a>,
              Siddhant Kharbanda, 
              Sarthak Arora, 
              <a href="https://www.linkedin.com/in/rroshanroy/">Roshan Roy</a>,
              Nishant Jain, 
              Akash Palrecha, 
              Tanav Shah, 
              Shray Mathur, 
              Ritik Mathur, 
              Abhijay Kemkar, 
              <strong>Anirudh Chakravarthy</strong>,
              <a href="https://zudi-lin.github.io/">Zudi Lin</a>,
              <a href="https://wdjang.github.io/">Won-Dong Jang</a>, 
              Yansong Tang, 
              <a href="https://songbai.site/">Song Bai</a>, 
              <a href="https://jamestompkin.com/">James Tompkin</a>, 
              <a href="https://www.robots.ox.ac.uk/~phst/">Philip H.S. Torr</a>, 
              <a href="https://vcg.seas.harvard.edu/people/hanspeter-pfister">Hanspeter Pfister</a>
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022
              <br>
              <a href="https://donglaiw.github.io/proj/youMVOS/">[project page]</a>
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_YouMVOS_An_Actor-Centric_Multi-Shot_Video_Object_Segmentation_Dataset_CVPR_2022_paper.pdf">[pdf]</a>
              
              <p></p>
              <p>
               We introduce a new dataset and benchmark, YouMVOS, for multi-shot video object segmentation.
            </p>
          </td>
        </tr>

        <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ddp_image'>
                <img src='images/Objprop_teaser.png' width="200"></div>
              <img src='images/Objprop_teaser.png' width="200">
            </div>
            <script type="text/javascript">
              function ddp_start() {
                document.getElementById('ddp_image').style.opacity = "1";
              }
      
              function ddp_stop() {
                document.getElementById('ddp_image').style.opacity = "0";
              }
              ddp_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/pdf/2111.07529.pdf">
              <papertitle>Object Propagation via Inter-Frame Attentions for Temporally Stable Video Instance Segmentation</papertitle>
            </a>
            <br>
            <strong>Anirudh Chakravarthy</strong>,
            <a href="https://wdjang.github.io/">Won-Dong Jang</a>,
            <a href="https://zudi-lin.github.io/">Zudi Lin</a>,
            <a href="https://donglaiw.github.io/">Donglai Wei</a>,
            <a href="https://songbai.site/">Song Bai</a>,
            <a href="https://vcg.seas.harvard.edu/people/hanspeter-pfister">Hanspeter Pfister</a>
            <br>
            <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>, 2021
            <br>
            <a href="https://omnomnom.vision.rwth-aachen.de/data/RobMOTS/workshop/papers/6/CameraReady/2021_CVPRW_VIS_CRC.pdf">[pdf]</a>
            <a href="https://arxiv.org/pdf/2111.07529.pdf">[arXiv]</a>
            <a href="https://github.com/anirudh-chakravarthy/ObjProp">[code]</a>
            
            <p></p>
            <p>
              We identify mask quality as a bottleneck for video instance segmentation. To overcome this, we propose an attention-based network to propagate missing object instances. Our method significantly outperforms previous state-of-the-art algorithms using the Mask R-CNN backbone, by achieving 36.0% mAP on the YouTube-VIS benchmark.
          </p>
        </td>
      </tr>

      <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
        <td style="padding:20px;width:30%;vertical-align:middle">
          <div class="one">
            <div class="two" id='ddp_image'>
              <img src='images/mrscatt_network.png' width="200"></div>
            <img src='images/mrscatt_network.png' width="200">
          </div>
          <script type="text/javascript">
            function ddp_start() {
              document.getElementById('ddp_image').style.opacity = "1";
            }
    
            function ddp_stop() {
              document.getElementById('ddp_image').style.opacity = "0";
            }
            ddp_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/papers/Chakravarthy_MRSCAtt_A_Spatio-Channel_Attention-Guided_Network_for_Mars_Rover_Image_Classification_CVPRW_2021_paper.pdf">
            <papertitle>MRSCAtt: A Spatio-Channel Attention-Guided Network for Mars Rover Image Classification</papertitle>
          </a>
          <br>
          <strong>Anirudh Chakravarthy*</strong>,
          <a href="https://www.linkedin.com/in/rroshanroy/">Roshan Roy*</a>,
          <a href="https://www.linkedin.com/in/praveen-ravirathinam/">Praveen Ravirathinam*</a>
          <br>
          <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>, 2021
          <br>
          <a href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/papers/Chakravarthy_MRSCAtt_A_Spatio-Channel_Attention-Guided_Network_for_Mars_Rover_Image_Classification_CVPRW_2021_paper.pdf">[pdf]</a>
          <a href="https://github.com/anirudh-chakravarthy/MRSCAtt">[code]</a>
          
          <p></p>
          <p>
            We propose a network, MRSCAtt (Mars Rover Spatial and Channel Attention), which jointly uses spatial and channel attention to accurately classify images. We use images taken by NASA's Curiosity rover on Mars as a dataset to show the superiority of our approach by achieving state-of-the-art results with 81.53% test set accuracy on the MSL Surface Dataset, outperforming other methods. 
        </p>
          
      </td>
    </tr>


    </tbody></table>

    <!-- EXPERIENCES -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Work Experience</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ddp_image'>
                <img src='images/amazon_logo.png' width="160"></div>
              <img src='images/amazon_logo.png' width="160">
            </div>
            <script type="text/javascript">
              function ddp_start() {
                document.getElementById('ddp_image').style.opacity = "1";
              }
      
              function ddp_stop() {
                document.getElementById('ddp_image').style.opacity = "0";
              }
              ddp_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Amazon AGI Labs</papertitle>
            <br>
            <em>Member of Technical Staff <span style="float:right;">Present</span></em>
            <br>
            
            <p></p>
            <p>
              Computer-use Agents (check out <a href='https://labs.amazon.science/blog/nova-act'>Nova Act</a>!)
          </p>
        </td>
      </tr>

        <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ddp_image'>
                <img src='images/cruise_logo.png' width="160"></div>
              <img src='images/cruise_logo.png' width="160">
            </div>
            <script type="text/javascript">
              function ddp_start() {
                document.getElementById('ddp_image').style.opacity = "1";
              }
      
              function ddp_stop() {
                document.getElementById('ddp_image').style.opacity = "0";
              }
              ddp_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Cruise LLC</papertitle>
            <br>
            <em>Senior Applied Scientist <span style="float:right;"></span></em>
            <br>
            
            <p></p>
            <p>
              Large Models for Long-tail Perception
          </p>
        </td>
      </tr>


      <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='ddp_image'>
              <img src='images/Harvard_logo.png' width="160"></div>
            <img src='images/Harvard_logo.png' width="160">
          </div>
          <script type="text/javascript">
            function ddp_start() {
              document.getElementById('ddp_image').style.opacity = "1";
            }
    
            function ddp_stop() {
              document.getElementById('ddp_image').style.opacity = "0";
            }
            ddp_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Visual Computing Group, Harvard University</papertitle>
          <br>
          <em>Research Intern <span style="float:right;"></span></em>
          <br>
          
          <p></p>
          <p>
            Video Instance Segmentation
        </p>
      </td>
    </tr>

    <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ddp_image'>
            <img src='images/uiuc_logo.png' width="160"></div>
          <img src='images/uiuc_logo.png' width="160">
        </div>
        <script type="text/javascript">
          function ddp_start() {
            document.getElementById('ddp_image').style.opacity = "1";
          }
  
          function ddp_stop() {
            document.getElementById('ddp_image').style.opacity = "0";
          }
          ddp_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Computer Vision and Robotics Lab, University of Illinois Urbana-Champaign</papertitle>
        <br>
        <em>Research Intern <span style="float:right;"></span></em>
        <br>
        
        <p></p>
        <p>
          Vital Parameter Estimation
      </p>
    </td>
  </tr>

  </tbody></table>

    <!-- PROJECTS -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Projects</heading>
      </td>
    </tr>
  </tbody></table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
      <td style="padding:20px;width:30%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ddp_image'>
            <img src='images/monodepth_relpose.png' width="200"></div>
          <img src='images/monodepth_relpose.png' width="200">
        </div>
        <script type="text/javascript">
          function ddp_start() {
            document.getElementById('ddp_image').style.opacity = "1";
          }

          function ddp_stop() {
            document.getElementById('ddp_image').style.opacity = "0";
          }
          ddp_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Self-Supervised Camera Pose Estimation with Geometric Consistency</papertitle>
          <br>
          <a href="files/Monodepth+RelPose.pdf">[pdf]</a>
          <a href="https://github.com/vanshajc/self-supervised-relpose">[code]</a>
        <p></p>
        <p>
          Existing camera pose estimation methods make use of ground-truth odometry as supervision, which may be expensive to obtain.
          In this work, we train a transformer-based pose estimation network in a self-supervised manner, leveraging advances in monocular depth estimation.
        </p>
    </td>
  </tr>

  <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
    <td style="padding:20px;width:30%;vertical-align:middle">
      <div class="one">
        <div class="two" id='ddp_image'>
          <img src='images/mvo_fusion_teaser.png' width="200"></div>
        <img src='images/mvo_fusion_teaser.png' width="200">
      </div>
      <script type="text/javascript">
        function ddp_start() {
          document.getElementById('ddp_image').style.opacity = "1";
        }

        function ddp_stop() {
          document.getElementById('ddp_image').style.opacity = "0";
        }
        ddp_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <papertitle>Is Monocular Vision Sufficient for Multi-View Visual Odometry?</papertitle>
        <br>
        <a href="files/MVO Fusion.pdf">[pdf]</a>
        <a href="https://github.com/neha-boloor/MVO-fusion">[code]</a>
      <p></p>
      <p>
        For visual localization, we often have multiple cameras mounted onto a robot which can be used to infer odometry (known as multi-view visual odometry).
         Existing works either heavily rely on the scene geometry or use complicated networks posing challenges for real-world generalization.
        In this work, we aim to develop simple yet strong baselines for multi-view visual odometry, by fusing estimates using monocular visual odometry.
    </p>
  </td>
  </tr>

  <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
  <td style="padding:20px;width:30%;vertical-align:middle">
    <div class="one">
      <div class="two" id='ddp_image'>
        <img src='images/multiperson_reconstruction_teaser.png' width="200"></div>
      <img src='images/multiperson_reconstruction_teaser.png' width="200">
    </div>
    <script type="text/javascript">
      function ddp_start() {
        document.getElementById('ddp_image').style.opacity = "1";
      }

      function ddp_stop() {
        document.getElementById('ddp_image').style.opacity = "0";
      }
      ddp_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
      <papertitle>Constrained Humanification: Improving Multi-Person Reconstruction Using Temporal Constraints</papertitle>
      <br>
      <a href="files/Multiperson.pdf">[pdf]</a>
      <a href="https://github.com/anirudh-chakravarthy/Flow-augmented-Multiperson-Reconstruction">[code]</a>
    <p></p>
    <p>
      Multi-person 3D reconstruction is challenging, yet no prior work aims to disambiguate inter-person occlusions using temporal information.
      Motivated by this, we leverage optical flow as a cue to improve 3D human pose estimation in crowded scenes.
  </p>
  </td>
  </tr>

  <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
    <td style="padding:20px;width:30%;vertical-align:middle">
      <div class="one">
        <div class="two" id='ddp_image'>
          <img src='images/gan_robustness_teaser.png' width="200"></div>
        <img src='images/gan_robustness_teaser.png' width="200">
      </div>
      <script type="text/javascript">
        function ddp_start() {
          document.getElementById('ddp_image').style.opacity = "1";
        }

        function ddp_stop() {
          document.getElementById('ddp_image').style.opacity = "0";
        }
        ddp_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <papertitle>Latent Space Robustness of Generative Models</papertitle>
        <br>
        <a href="https://sites.google.com/andrew.cmu.edu/16824-spring22-group7/">[project page]</a>
        <a href="https://github.com/anirudh-chakravarthy/GAN-Robustness">[code]</a>
      <p></p>
      <p>
        Generative models such as StyleGAN have shown very promising results. However, while using such GANs for face generation, we often encounter cases of non-photorealistic generations (e.g: artifacts, not face-like, etc.). 
        In this project, we aim to formally establish the existence of such failure modes in GANs.
    </p>
  </td>
  </tr>

  </tbody></table>
				
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>News</heading>
            </td>
          </tr>
					
          <tr>
            <td>
              <strong>[Apr 2025]</strong> I joined <a href="https://labs.amazon.science/">Amazon AGI SF Labs</a> as a Member of Technical Staff!<br>
              <strong>[Sept 2024]</strong> Our work on Lidar Panoptic Segmentation in an Open World is accepted into IJCV 2024!<br>
              <strong>[Feb 2023]</strong> I joined <a href="https://www.getcruise.com/">Cruise</a> full-time!<br>
              <strong>[Dec 2022]</strong> I graduated from <a href="https://www.cmu.edu/">Carnegie Mellon University </a> with a Masters in Computer Vision!<br>
              <strong>[May 2022]</strong> I'll be joining <a href="https://www.getcruise.com/">Cruise</a> over the summer.<br>
              <strong>[Mar 2022]</strong> Our work and dataset on multi-shot video object segmentation is accepted to CVPR 2022!<br>
              <strong>[Oct 2021]</strong> I'll be joining the <a href="https://labs.ri.cmu.edu/argo-ai-center/">CMU Argo AI Center for Autonomous Vehicle Research</a> as a Research Collaborator under the guidance of <a href="http://www.cs.cmu.edu/~deva/">Prof. Deva Ramanan</a>.<br>
              <strong>[Aug 2021]</strong> I began my Masters in Computer Vision (MSCV) at the <a href="https://www.ri.cmu.edu/">Robotics Institute</a>, <a href="https://www.cmu.edu/">Carnegie Mellon University </a>(CMU).<br>
              <strong>[May 2021]</strong> I graduated from <a href="https://www.bits-pilani.ac.in/">BITS Pilani, India</a> with a Bachelor's in Computer Science.<br>
              <strong>[Apr 2021]</strong> Two papers accepted at CVPRW 2021!<br>
              <strong>[Aug 2020]</strong> I'll be joining <a href="https://vision.ai.illinois.edu/">UIUC CVRL</a> under the guidance of <a href="https://vision.ai.illinois.edu/narendra-ahuja/">Prof. Narendra Ahuja</a> as a research intern.<br>
              <strong>[May 2020]</strong> I'll be joining <a href="https://vcg.seas.harvard.edu/">Harvard VCG</a> under the guidance of <a href="https://vcg.seas.harvard.edu/people/hanspeter-pfister">Prof. Hanspeter Pfister</a> for my undergraduate thesis.<br>
          </td>
            </tr>

        </tbody></table> -->

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Source code from <a href="https://github.com/jonbarron/jonbarron_website"> Jon Barron</a>
                	      
                <br>
                </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

  <small><center>
    This page has been accessed at least
    <a href="http://stuff.mit.edu/doc/counter-howto.html"><img
            src="http://stuff.mit.edu/cgi/counter/anirudhchakravarthy" alt="several"></a>
    times since 30th Dec 2022.
</center></small>

</body>

</html>
